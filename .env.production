# ============================================================================
# PRODUCTION ENVIRONMENT CONFIGURATION
# ============================================================================
# This file contains production-ready settings with placeholders.
# IMPORTANT: Replace ALL placeholder values before deploying to production!
# Never commit actual credentials to version control.
# ============================================================================


# ============================================================================
# API KEYS & SECRETS
# ============================================================================
# ⚠️ CRITICAL: These MUST be replaced with actual production values
# Keep these secure and never commit to version control

# OpenAI API Key (Get from: https://platform.openai.com/api-keys)
OPENAI_API_KEY=your_openai_api_key_here

# Pinecone API Key (Get from: https://www.pinecone.io/)
PINECONE_API_KEY=your_pinecone_api_key_here

# JWT Secret Key (Generate with: openssl rand -hex 32)
# ⚠️ MUST be different from development!
JWT_SECRET_KEY=your_production_jwt_secret_key_here


# ============================================================================
# DATABASE CONFIGURATION
# ============================================================================

# PostgreSQL Database
# Format: postgresql+asyncpg://username:password@host:port/database
# Replace with production database credentials
DATABASE_URL=postgresql+asyncpg://prod_user:prod_password@prod-db-host:5432/chatbot_prod_db

# Redis (for docstore and chat memory)
# Use production Redis instance (consider managed service like Redis Cloud)
REDIS_HOST=prod-redis-host
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=your_redis_password_here


# ============================================================================
# EXTERNAL SERVICES CONFIGURATION
# ============================================================================

# --- OpenAI Configuration ---
OPENAI_MODEL=gpt-4o-mini
OPENAI_TEMPERATURE=0.5

# --- Pinecone Vector Database ---
# Use production Pinecone environment
PINECONE_ENVIRONMENT=us-east-1
PINECONE_INDEX_NAME=production-index
PINECONE_DIMENSION=3072
PINECONE_METRIC=cosine

# --- Cloudflare R2 Storage ---
# ⚠️ Use production R2 bucket and credentials
R2_ACCOUNT_ID=your_r2_account_id_here
R2_ACCESS_KEY_ID=your_r2_access_key_id_here
R2_SECRET_ACCESS_KEY=your_r2_secret_access_key_here
R2_BUCKET_NAME=chatbot-production


# ============================================================================
# APPLICATION SETTINGS
# ============================================================================

APP_NAME=Multi-modal RAG API
APP_VERSION=1.0.0
API_V1_PREFIX=/api/v1


# ============================================================================
# PDF PROCESSING CONFIGURATION
# ============================================================================

# Upload and Storage
PDF_UPLOAD_DIR=./content
PDF_MAX_FILE_SIZE=10485760
PDF_RETENTION_DAYS=7

# Chunking Strategy
PDF_CHUNKING_STRATEGY=by_title
PDF_MAX_CHARACTERS=10000
PDF_COMBINE_TEXT_UNDER_N_CHARS=2000
PDF_NEW_AFTER_N_CHARS=6000

# OCR / Tesseract (comma or plus-separated language codes: eng, ind, eng+ind)
OCR_LANGUAGES=eng+ind


# ============================================================================
# RAG & AI CONFIGURATION
# ============================================================================

# Retrieval Settings
RAG_TOP_K=4
RAG_BATCH_CONCURRENCY=1

# --- RAG Prompt Configuration - BSI UII IT Support Chatbot ---

# System prompt defines the chatbot's role, behavior, and response style
RAG_SYSTEM_PROMPT="You are an expert in IT Support BSI UII, having worked in the field for over a decade, and now you will notify users who have problems related to IT support.\n\nProvide step-by-step solutions to problems experienced by users from the knowledge base. The focus is on solving user problems, IT support obstacles faced, and providing solutions to obstacles.\n\nThis answer is intended to be a solution to obstacles for BSI UII IT support chatbot users. You may want to consider not answering questions outside the knowledge base.\n\nPresent the answer in a structured way:\n- Start with a warm greeting\n- Follow with a detailed solution\n- Use numbered lists (1. 2. 3.) for step-by-step instructions\n- Use bullet points (-) for feature lists\n- When providing URLs, use only clean text format like: 'Kunjungi office.com untuk informasi lebih lanjut.' without HTML markup\n\nMaintain a formal and academic tone appropriate for an academic audience. Ensure clarity and precision in providing solutions and ensure each step is clear and actionable.\n\nIf the question refers to previous conversation (using words like 'it', 'that', 'this'), use the chat history to understand what the user is referring to."

# Prompt template when chat history exists (multi-turn conversation)
RAG_PROMPT_WITH_HISTORY="Context from knowledge base:\n{context_text}\n\nCurrent question: {question}\n\nBased on the context above and conversation history, provide a structured answer following these guidelines:\n1. Start with a warm greeting\n2. Provide step-by-step solution using numbered lists\n3. Use bullet points for features or lists\n4. Ensure each step is clear and actionable\n5. Maintain formal and academic tone"

# Prompt template for first-time queries (no chat history)
RAG_PROMPT_WITHOUT_HISTORY="Answer the question based only on the following context from the knowledge base, which can include text, tables, and images.\n\nContext:\n{context_text}\n\nQuestion: {question}\n\nProvide a structured answer following these guidelines:\n1. Start with a warm greeting\n2. Provide step-by-step solution using numbered lists (1. 2. 3.)\n3. Use bullet points (-) for feature lists\n4. When providing URLs, use clean text format without HTML markup\n5. Maintain formal and academic tone appropriate for BSI UII\n6. Ensure each step is clear and actionable\n\nIf the information is not available in the knowledge base above, politely inform the user that the question is outside the scope of available information."

# Chat Memory Settings
CHAT_HISTORY_TTL=7200
CHAT_MAX_MESSAGES=10


# ============================================================================
# SECURITY & AUTHENTICATION
# ============================================================================

# JWT Configuration
JWT_ALGORITHM=HS256
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30


# ============================================================================
# CORS & RATE LIMITING
# ============================================================================

# CORS Configuration
# ⚠️ Replace with actual production frontend URLs
# Example: https://chatbot.bsi.uii.ac.id,https://api.bsi.uii.ac.id
CORS_ORIGINS=https://your-production-domain.com
CORS_ALLOW_CREDENTIALS=true

# Rate Limiting (Format: "number/unit" where unit: second, minute, hour, day)
# Consider stricter limits for production to prevent abuse
RATE_LIMIT_LOGIN=5/minute
RATE_LIMIT_REGISTER=3/hour
RATE_LIMIT_QUERY=20/minute
RATE_LIMIT_UPLOAD=5/hour
RATE_LIMIT_API_KEY_CREATE=10/hour
RATE_LIMIT_API_KEY_LIST=30/minute
RATE_LIMIT_API_KEY_DELETE=10/minute
RATE_LIMIT_CHAT_HISTORY=30/minute
RATE_LIMIT_DEFAULT=100/minute
RATE_LIMIT_STORAGE_DB=1
# RATE_LIMIT_STORAGE_URI=redis://:password@prod-redis-host:6379/1


# ============================================================================
# SERVER & ENVIRONMENT
# ============================================================================

# Server Configuration
# ⚠️ PRODUCTION SETTINGS - Do not change unless necessary
SERVER_HOST=0.0.0.0
SERVER_PORT=8000
SERVER_RELOAD=false
SERVER_LOG_LEVEL=warning

# API Documentation
# ⚠️ SECURITY: Set to false in production to hide API docs
ENABLE_DOCS=false
ENABLE_REDOC=false


# ============================================================================
# OPTIONAL SERVICES (for debugging/tracing)
# ============================================================================

# LangSmith - Useful for production monitoring and debugging
# Uncomment and configure for production tracing
# LANGCHAIN_API_KEY=your_langsmith_production_key_here
# LANGCHAIN_TRACING_V2=true
# LANGCHAIN_PROJECT=multimodal-rag-production


# ============================================================================
# PRODUCTION-SPECIFIC SETTINGS
# ============================================================================

# Matplotlib Configuration (if deploying to specific server path)
# Uncomment and adjust if needed for your deployment environment
# MPLCONFIGDIR=/path/to/production/matplotlib_config


# ============================================================================
# DEPLOYMENT CHECKLIST
# ============================================================================
# Before deploying to production, ensure you have:
# [ ] Replaced ALL placeholder API keys and secrets
# [ ] Updated DATABASE_URL with production credentials
# [ ] Set CORS_ORIGINS to actual production domain(s)
# [ ] Verified ENABLE_DOCS=false and ENABLE_REDOC=false
# [ ] Confirmed SERVER_RELOAD=false
# [ ] Set appropriate SERVER_LOG_LEVEL (warning or error)
# [ ] Configured production Redis instance
# [ ] Set up production Pinecone index
# [ ] Configured production R2 bucket
# [ ] Generated new JWT_SECRET_KEY (different from dev)
# [ ] Tested all external service connections
# [ ] Set up monitoring and alerting (optional: LangSmith)
# [ ] Reviewed and adjusted rate limits for production load
# [ ] Backed up this configuration securely
# ============================================================================
